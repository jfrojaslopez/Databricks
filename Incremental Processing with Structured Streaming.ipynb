{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7af853e2-b63b-44b8-8537-720bf6909557",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Incremental Processing with Structured Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e2ec323-703f-4d17-8dae-8efcd9114b27",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Streaming Data Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ed3f87f-1766-4d5a-a57f-af323e916559",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style=\"background-color: lightblue; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "**¿Qué son los datos en flujo?**\n",
    "\n",
    "Datos ilimitados generados continuamente\n",
    "\n",
    "**Fuentes de datos típicas**\n",
    "\n",
    "1. Fuentes de datos de cambios en la base de datos\n",
    "2. Flujos de clics\n",
    "3. Registros de máquinas y aplicaciones\n",
    "4. Eventos de aplicación\n",
    "5. Datos móviles y de IoT\n",
    "\n",
    "***La gran mayoría de los datos del mundo son datos en streaming.***\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8d24863-7c20-4d22-b9f8-a48462e4a07a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Notas:**\n",
    "\n",
    "Los datos en flujo o streaming data son un tipo de datos generados de forma continua y sin límite, típicamente en pequeñas cantidades, que son procesados en tiempo real o casi en tiempo real. Estos datos provienen de diversas fuentes y suelen reflejar eventos que ocurren en sistemas, aplicaciones o dispositivos. Los datos en flujo son fundamentales en muchos escenarios donde la información debe ser procesada o monitoreada de manera inmediata.\n",
    "\n",
    "**Características clave de los datos en flujo:**\n",
    "\n",
    "- Generación continua: Los datos no se producen en bloques predefinidos, sino que son generados y transmitidos de forma constante.\n",
    "- Bajo volumen por evento: Cada evento individual generalmente contiene pocos datos, pero el flujo continuo de eventos puede resultar en un gran volumen con el tiempo.\n",
    "- Procesamiento en tiempo real: Los datos deben ser procesados de inmediato, sin esperar a que se almacenen en una base de datos tradicional.\n",
    "\n",
    "**Fuentes típicas de datos en flujo:**\n",
    "\n",
    "- **DB change data feeds:** Cambios en bases de datos que se envían en tiempo real, por ejemplo, modificaciones de registros.\n",
    "- **Clickstreams:** Datos generados por los clics de los usuarios en sitios web o aplicaciones, permitiendo el análisis de navegación en tiempo real.\n",
    "- **Logs de máquinas y aplicaciones:** Información continua generada por sistemas informáticos, aplicaciones o dispositivos de hardware que registran eventos de sistema.\n",
    "- **Eventos de aplicaciones:** Eventos generados por aplicaciones que requieren ser monitoreados o respondidos rápidamente, como alertas de sistemas.\n",
    "- **Datos de dispositivos móviles e IoT:** Sensores, dispositivos conectados y aplicaciones móviles que generan datos constantemente, que pueden abarcar desde lecturas de sensores hasta actualizaciones de posición GPS.\n",
    "\n",
    "**Importancia:**\n",
    "\n",
    "Los datos en flujo representan una gran parte del volumen de datos generado en el mundo moderno, ya que muchas aplicaciones actuales dependen de la capacidad de procesar información en tiempo real, como en sistemas financieros, control de dispositivos IoT, monitoreo de aplicaciones web y análisis de comportamiento de usuarios en línea.\n",
    "\n",
    "Estos datos requieren tecnologías y plataformas especializadas para su procesamiento, como **Apache Kafka, Amazon Kinesis, Azure Event Hubs**, y otras herramientas diseñadas para soportar la ingesta y procesamiento de eventos a gran escala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2f96f10-d352-4da5-a1bd-93fb6322cf3e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style=\"display: flex; background-color: lightblue; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "**¿Qué es el procesamiento de flujos?**\n",
    "\n",
    "  <div style=\"flex: 50%; padding: 10px;\">\n",
    "\n",
    "  El tratamiento tradicional de datos por lotes es puntual y limitado.\n",
    "\n",
    "  </div>\n",
    "\n",
    "  <div style=\"flex: 50%; padding: 10px;\">\n",
    "\n",
    "  El procesamiento en flujo es continuo e ilimitado\n",
    "\n",
    "  </div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b9687e4-08db-4b97-bc01-e0bb23798114",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style=\"background-color: lightblue; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "**Procesamiento de Stream**\n",
    "\n",
    "¿Por qué se está popularizando el procesamiento de flujos?\n",
    "\n",
    "- **Velocidad y volumen de los datos:** El aumento de la velocidad y el volumen de los datos requiere un procesamiento continuo e incremental - no se pueden procesar todos los datos en un lote programado\n",
    "\n",
    "- **Análisis en tiempo real:** Las empresas exigen acceso a datos nuevos para obtener información práctica y tomar mejores decisiones empresariales con mayor rapidez.\n",
    "\n",
    "- **Aplicaciones operativas:** Las aplicaciones críticas necesitan datos en tiempo real para una respuesta eficaz e instantánea.\n",
    "\n",
    "***La gran mayoría de los datos del mundo son datos en flujo.***\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc5c0cc2-de03-4dad-b9b1-2374a76c095f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Casos prácticos de procesamiento de flujos\n",
    "\n",
    "El procesamiento de flujos es un componente clave de las aplicaciones de big data en todas las industrias\n",
    "\n",
    "1. Notificaciones\n",
    "2. Informes en tiempo real\n",
    "3. ETL incremental\n",
    "4. Actualización de datos para servir en tiempo real\n",
    "5. Toma de decisiones en tiempo real\n",
    "6. ML en línea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80a890f8-89de-4801-8c32-ba5c2187a28e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Notas:**\n",
    "\n",
    "Los casos prácticos de procesamiento de flujos son esenciales para aplicaciones de big data, ya que permiten el manejo de grandes volúmenes de datos que se generan en tiempo real. Aquí tienes una explicación más detallada de cada caso:\n",
    "\n",
    "1. **Notificaciones:**\n",
    "\n",
    "  - **Ejemplo:** Plataformas como las redes sociales o aplicaciones de mensajería envían notificaciones cuando los usuarios realizan ciertas acciones (nuevos mensajes, comentarios, etc.).\n",
    "\n",
    "  - **Requisito de flujo:** Detectar eventos en tiempo real para desencadenar notificaciones instantáneas.\n",
    "\n",
    "2. **Informes en tiempo real:**\n",
    "\n",
    "  - **Ejemplo:** Dashboards que muestran métricas clave de rendimiento en tiempo real (como Google Analytics o herramientas de monitoreo de sistemas).\n",
    "\n",
    "  - **Requisito de flujo:** Procesar y mostrar datos a medida que son generados, sin demoras, para proporcionar visibilidad continua.\n",
    "\n",
    "3. **ETL incremental:**\n",
    "\n",
    "  - **Ejemplo:** Actualización continua de datos en un almacén de datos, donde solo se procesan y cargan los datos nuevos o modificados, optimizando recursos y tiempo.\n",
    "\n",
    "  - **Requisito de flujo:** Transformar y cargar datos de manera eficiente a medida que se reciben, en lugar de realizar cargas completas.\n",
    "\n",
    "4. **Actualización de datos para servir en tiempo real:**\n",
    "\n",
    "  - **Ejemplo:** Servicios como motores de recomendación (Netflix, Amazon) que actualizan los datos de usuarios y recomendaciones con cada nueva interacción.\n",
    "  - **Requisito de flujo:** Los modelos de datos o bases de datos deben ser actualizados con las interacciones en tiempo real para mejorar la experiencia del usuario.\n",
    "\n",
    "5. **Toma de decisiones en tiempo real:**\n",
    "\n",
    "  - **Ejemplo:** Algoritmos de detección de fraude en sistemas financieros que deben analizar transacciones y detectar comportamientos anómalos en cuestión de milisegundos.\n",
    "  - **Requisito de flujo:** Procesamiento inmediato de datos para actuar ante situaciones críticas, como bloquear transacciones sospechosas.\n",
    "\n",
    "6. **ML en línea:**\n",
    "\n",
    "  - **Ejemplo:** Aplicaciones de aprendizaje automático que se actualizan de forma continua con nuevos datos, mejorando sus predicciones de manera incremental (publicidad personalizada, precios dinámicos, etc.).\n",
    "  - **Requisito de flujo:** Procesar y alimentar los modelos con datos nuevos sin necesidad de volver a entrenar el modelo desde cero.\n",
    "\n",
    "\n",
    "Cada uno de estos casos utiliza herramientas de procesamiento de flujos como **Apache Kafka, Apache Flink, Spark Streaming o Databricks Structured Streaming**, que permiten manejar el flujo continuo de datos y tomar decisiones basadas en los eventos que ocurren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "884e9278-724e-4d76-8311-9dc49504ee9a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style=\"display: flex; background-color: lightblue; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "**Conjunto de datos delimitado frente a conjunto de datos no delimitado**\n",
    "\n",
    "  <div style=\"flex: 50%; padding: 10px;\">\n",
    "\n",
    "  **Datos limitados**\n",
    "\n",
    "  - Tiene una estructura finita e invariable en el momento del procesamiento\n",
    "  - El orden es estático\n",
    "  - **Analogía:** Vehículos en un aparcamiento.\n",
    "\n",
    "  </div>\n",
    "\n",
    "  <div style=\"flex: 50%; padding: 10px;\">\n",
    "\n",
    "  **Datos no limitados**\n",
    "\n",
    "  - Tiene una estructura infinita y continuamente cambiante en el momento del procesamiento.\n",
    "  - El orden no siempre es secuencial.\n",
    "  - **Analogía:** Vehículos en una autopista\n",
    "\n",
    "  </div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f635834e-36d8-4b2c-8abf-d9d68dd06751",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Notas**\n",
    "\n",
    "En el contexto del procesamiento de datos, los términos \"bounded\" y \"unbounded\" se refieren a los tipos de conjuntos de datos con los que se trabaja, y estos conceptos son clave en la elección de enfoques y herramientas de procesamiento de datos. A continuación, te explico ambos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b447f597-00b3-4c48-aea6-9fec474e1436",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###**Bounded Dataset (Conjunto de Datos Acotado):**\n",
    "\n",
    "**Definición:** Un conjunto de datos es considerado \"bounded\" si tiene un tamaño finito y limitado. Es decir, todos los datos ya están disponibles desde el principio, o al menos se sabe cuándo se completa la llegada de los datos.\n",
    "\n",
    "**Ejemplo:**\n",
    "- Una tabla de una base de datos relacional donde todos los registros ya están presentes.\n",
    "- Un archivo CSV que contiene un número finito de registros.\n",
    "- Un lote de transacciones históricas de ventas en un archivo.\n",
    "\n",
    "**Uso:** Este tipo de conjunto de datos se maneja en procesamiento por lotes (batch processing), ya que no se espera que los datos cambien después de que se inicie el procesamiento.\n",
    "\n",
    "**Herramientas comunes:** Apache Hadoop, Apache Spark (batch mode), SQL tradicional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31c63c93-9be1-4973-b58c-85d7825aa3f5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###**Unbounded Dataset (Conjunto de Datos No Acotado):**\n",
    "\n",
    "**Definición:** Un conjunto de datos es considerado \"unbounded\" si se trata de un flujo continuo de datos sin un final conocido. Los datos se generan de manera continua y teóricamente infinita, lo que requiere procesamiento en tiempo real o cercano al tiempo real.\n",
    "\n",
    "**Ejemplo:**\n",
    "- Datos generados por sensores IoT en tiempo real.\n",
    "- Transacciones financieras o clics en sitios web que se registran de manera constante.\n",
    "- Flujos de logs de servidores web o sistemas de monitoreo de red.\n",
    "\n",
    "**Uso:** Este tipo de conjunto de datos se maneja mediante procesamiento de flujos (stream processing), donde los datos se procesan a medida que llegan, en lugar de esperar a que se complete un lote.\n",
    "\n",
    "**Herramientas comunes:** Apache Kafka, Apache Flink, Spark Streaming, Databricks Structured Streaming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9638938-69b9-4dad-9bc1-77cd9772ffd9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###**Diferencias clave:**\n",
    "\n",
    "| **Característica**  | **Bounded Dataset**  | **Unbounded Dataset**  |\n",
    "|---------------------|----------------------|------------------------|\n",
    "| **Tamaño**          | Finito               | Infinito (flujo continuo) |\n",
    "| **Procesamiento**    | Procesamiento por lotes (batch) | Procesamiento de flujo (streaming) |\n",
    "| **Finalización**     | Conocido, procesamiento tiene un fin | Desconocido, datos siguen llegando |\n",
    "| **Latencia**         | Típicamente alta (el procesamiento ocurre al completar el lote) | Baja, el procesamiento es inmediato |\n",
    "| **Casos de uso**     | Informes históricos, procesamiento de grandes archivos o bases de datos | Monitorización en tiempo real, toma de decisiones instantánea |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09942d65-bd49-4fcb-bdaf-f5c9b92d1c40",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "###**Ejemplos de aplicación:**\n",
    "\n",
    "**Bounded Dataset:** Cuando realizas análisis sobre todos los datos históricos de una empresa, ya que puedes cargar todo el conjunto de datos a la vez y ejecutar consultas o transformaciones.\n",
    "\n",
    "**Unbounded Dataset:** Cuando se realiza el monitoreo de eventos de una red de servidores, donde las alertas deben dispararse en tiempo real ante fallos o actividades anómalas."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Incremental Processing with Structured Streaming",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
